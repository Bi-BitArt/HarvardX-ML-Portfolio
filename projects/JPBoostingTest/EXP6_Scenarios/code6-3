# [Cell1]

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Extract features
features = ["annual_income", "savings_rate"]
X_income_save = X_test_shock[features].copy()

# KMeans clustering (3 clusters)
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_income_save)

# Add results to dataframe
X_income_save["Cluster"] = clusters

# Visualization
plt.figure(figsize=(8,6))
for cluster in range(3):
    subset = X_income_save[X_income_save["Cluster"] == cluster]
    plt.scatter(subset["annual_income"], subset["savings_rate"], label=f"Cluster {cluster}", alpha=0.6)

# Show cluster centroids
centers = kmeans.cluster_centers_
plt.scatter(centers[:,0], centers[:,1], c="black", s=200, marker="X", label="Centroids")

plt.xlabel("Annual Income")
plt.ylabel("Savings Rate")
plt.title("Clustering by Income & Savings Rate (3 clusters)")
plt.legend()
plt.show()

# [Cell2]

import numpy as np

# Extract Cluster 1 (Orange)
cluster1 = X_test_shock[clusters == 1]

# Calculate mean for numeric features
cluster1_mean = cluster1.mean()
overall_mean = X_test_shock.mean()

# Compute differences
diff = (cluster1_mean - overall_mean).sort_values(ascending=False)

# Select top 10 features
top_features = diff.head(10)

import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
colors = ["red" if v > 0 else "blue" for v in top_features.values]
top_features.plot(kind="barh", color=colors)
plt.title("Cluster 1 (Low Income × Low Savings) - Top Feature Differences")
plt.xlabel("Difference from Overall Mean")
plt.gca().invert_yaxis()
plt.show()

# [Cell3]

  # === Cluster-based, Multi-dimensional Policy (budget = universal total) ===
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans

def fit_income_savings_clusters(X_train, n_clusters=3,
                                income_col="annual_income", savings_col="savings_rate",
                                random_state=42):
    """Fit KMeans on income and savings rate (training set)."""
    Xk = X_train[[income_col, savings_col]].copy()
    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=random_state)
    kmeans.fit(Xk)
    return kmeans

def pick_vulnerable_cluster(kmeans, X_ref,
                            income_col="annual_income", savings_col="savings_rate"):
    """Pick the most vulnerable cluster: lowest average income and savings rate."""
    # Assign clusters
    labels = kmeans.predict(X_ref[[income_col, savings_col]])
    df = X_ref[[income_col, savings_col]].copy()
    df["cluster"] = labels
    # Vulnerable = cluster with lowest average income & savings
    grp = df.groupby("cluster")[[income_col, savings_col]].mean()
    vuln_cluster = (grp.rank(ascending=True).sum(axis=1)).idxmin()
    return labels, vuln_cluster

def apply_cluster_multidim_policy(X_after_shock,
                                  kmeans, vuln_cluster,
                                  income_col="annual_income", savings_col="savings_rate",
                                  total_budget_per_hh=100_000,
                                  cols_available=None):
    """Distribute the universal budget only within the vulnerable cluster by need;
       also apply non-cash structural support interventions.
    """
    Xp = X_after_shock.copy()
    n_total = len(Xp)
    total_budget = float(total_budget_per_hh) * n_total

    # Assign clusters on the (shock) set
    labels = kmeans.predict(Xp[[income_col, savings_col]])
    mask = (labels == vuln_cluster)

    # If no households in the vulnerable cluster, return unchanged
    if mask.sum() == 0:
        return Xp, labels

    # ---- Need score (higher => more cash) ----
    # Normalize: income (lower is worse), savings (lower is worse),
    # debt_to_income (higher is worse), financial_literacy (lower is worse).
    def norm_series(s):
        s = s.astype(float)
        mn, mx = s.min(), s.max()
        return (s - mn) / (mx - mn + 1e-9)

    need = pd.Series(0.0, index=Xp.index)
    # weights (tuneable)
    w = {"income": 0.35, "savings": 0.25, "dti": 0.25, "finlit": 0.15}

    # Income (lower = worse) → (1 - norm)
    if income_col in Xp.columns:
        need += w["income"] * (1.0 - norm_series(Xp[income_col]))
    if savings_col in Xp.columns:
        need += w["savings"] * (1.0 - norm_series(Xp[savings_col]))
    if "debt_to_income" in Xp.columns:
        need += w["dti"] * norm_series(Xp["debt_to_income"])
    if "financial_literacy" in Xp.columns:
        need += w["finlit"] * (1.0 - norm_series(Xp["financial_literacy"]))

    # Keep only vulnerable cluster
    need_v = need.where(mask, other=0.0)
    need_sum = need_v.sum()
    if need_sum <= 0:
        # fallback: equal split within cluster
        grants = pd.Series(0.0, index=Xp.index)
        grants[mask] = total_budget / mask.sum()
    else:
        grants = total_budget * (need_v / need_sum)

    # Apply cash grant as income boost
    if income_col in Xp.columns:
        Xp[income_col] = Xp[income_col].astype(float) + grants

    # ---- Non-cash structural tweaks (only within vulnerable cluster) ----
    if "financial_literacy" in Xp.columns:
        low_fin = (Xp["financial_literacy"] < 0.35) & mask
        Xp.loc[low_fin, "financial_literacy"] = np.clip(
            Xp.loc[low_fin, "financial_literacy"] + 0.20, 0, 1
        )

    if "foreign_born" in Xp.columns and "digital_access" in Xp.columns:
        fb = (Xp["foreign_born"] == 1) & mask
        Xp.loc[fb, "digital_access"] = np.clip(
            Xp.loc[fb, "digital_access"] + 0.20, 0, 1
        )

    if "debt_to_income" in Xp.columns:
        high_dti = (Xp["debt_to_income"] > 0.4) & mask
        Xp.loc[high_dti, "debt_to_income"] = np.clip(
            Xp.loc[high_dti, "debt_to_income"] - 0.10, 0, None
        )

    if "late_payment_12m" in Xp.columns:
        Xp.loc[mask, "late_payment_12m"] = np.clip(
            Xp.loc[mask, "late_payment_12m"] - 0.05, 0, 1
        )

    if "employment_status" in Xp.columns:
        # one-step improvement for vulnerable cluster
        Xp.loc[mask, "employment_status"] = np.maximum(
            0, Xp.loc[mask, "employment_status"].astype(int) - 1
        )

    return Xp, labels

# ====== Run end-to-end ======
# 1) Fit clusters on TRAIN (pre-shock)
kmeans = fit_income_savings_clusters(X_train, n_clusters=3,
                                     income_col="annual_income", savings_col="savings_rate")

# 2) Choose vulnerable cluster using the SHOCK set as reference (post-shock features)
labels_shock, vuln_cluster = pick_vulnerable_cluster(
    kmeans, X_test_shock, income_col="annual_income", savings_col="savings_rate"
)
print("Vulnerable cluster id:", vuln_cluster)

# 3) Apply policy to SHOCK set with SAME total budget as universal ¥100k
X_policy_cluster, labels_after = apply_cluster_multidim_policy(
    X_test_shock, kmeans, vuln_cluster,
    income_col="annual_income", savings_col="savings_rate",
    total_budget_per_hh=100_000
)

# 4) Evaluate vs. SHOCK baseline (NOT vs. clean baseline)
res_cluster_policy = eval_policy_shift(
    model,
    X_test_shock,           # baseline under shock
    X_policy_cluster,       # after cluster-based policy
    y_test,
    label="Cluster-based (cash + structural)"
)

# 5) Heatmap helper to guarantee axes 0..4 appear
import numpy as np, matplotlib.pyplot as plt, seaborn as sns
def heatmap_full_classes(trans_df, title, fname=None):
    idx = np.arange(5)
    trans_df = trans_df.copy()
    # reindex rows and cols to 0..4
    trans_df = trans_df.reindex(index=idx, columns=idx, fill_value=0.0)
    plt.figure(figsize=(6,5))
    sns.heatmap(trans_df, annot=True, fmt=".1f", cmap="Blues", cbar=False)
    plt.title(title)
    plt.xlabel("Predicted (After Policy)")
    plt.ylabel("Predicted (After Shock)")
    if fname:
        plt.tight_layout(); plt.savefig(fname, dpi=160)
    plt.show()

heatmap_full_classes(res_cluster_policy["trans"],
                     "Class Transition Matrix (Cluster-based Policy)",
                     fname="cluster_policy_heatmap.png")
