# [Cell1] Define external shock function (safer & reproducible)
import numpy as np
import pandas as pd

def apply_external_shock(X_df, seed: int = 42):
    Xs = X_df.copy()

    # --- Sector-specific income shock ---
    if "sector" in Xs.columns and "annual_income" in Xs.columns:
        # Explicit mapping (adjust if necessary)
        sec_hit = {
            0: 0.75,  # heavy hit  -25%
            1: 0.75,  # heavy hit  -25%
            2: 0.85,  # medium     -15%
            3: 0.85,  # medium     -15%
            # others   -5%
        }
        factors = Xs["sector"].map(lambda s: sec_hit.get(s, 0.95))
        Xs["annual_income"] = Xs["annual_income"] * factors

        # Guard against impossible values
        Xs["annual_income"] = Xs["annual_income"].clip(lower=0)

    # --- Interest rate shock (+2pp) ---
    if "interest_rate_personal" in Xs.columns:
        Xs["interest_rate_personal"] = (Xs["interest_rate_personal"] + 0.02).clip(lower=0)

    # --- Employment shock: move 20% to more precarious category (ordinal-encoded) ---
    if "employment_status" in Xs.columns:
        rng = np.random.RandomState(seed)
        idx = rng.rand(len(Xs)) < 0.2
        # Clip at upper bound (assuming higher = more precarious)
        Xs.loc[idx, "employment_status"] = np.minimum(
            Xs.loc[idx, "employment_status"] + 1,
            Xs["employment_status"].max()
        )

    return Xs


# [Cell2] Apply shock to test set
X_test_shock = apply_external_shock(X_test, seed=42)

# [Cell3] Evaluate baseline vs shock
from sklearn.metrics import roc_auc_score

# Baseline predictions
y_pred_base = model.predict(X_test)
y_prob_base = model.predict_proba(X_test)
auc_base = roc_auc_score(y_test, y_prob_base, multi_class="ovr", average="macro")

# Shock predictions (default: use y_test as ground truth)
y_pred_shock = model.predict(X_test_shock)
y_prob_shock = model.predict_proba(X_test_shock)

# If a post-shock ground truth (y_test_shock) exists, replace it here
# y_true_for_shock = y_test_shock
y_true_for_shock = y_test

auc_shock = roc_auc_score(y_true_for_shock, y_prob_shock, multi_class="ovr", average="macro")

print("== Baseline ==")
print("ROC AUC (macro OVR):", auc_base)
print("\n== After Shock ==")
print("ROC AUC (macro OVR):", auc_shock)
print("\nΔ AUC:", auc_shock - auc_base)


# [Cell4] Transition matrix (predicted class changes in %)
trans_mat = pd.crosstab(
    y_pred_base, y_pred_shock,
    rownames=["Predicted (Baseline)"], colnames=["Predicted (Shock)"],
    normalize="index"
) * 100

print("\nTransition matrix (%):")
print(trans_mat.round(1))


# [Cell5] Prominent changes in features (concise)
def pct(x): return f"{x*100:+.1f}%"
def pp(x):  return f"{x*100:+.1f} pp"

bullets = []
delta = X_test_shock.copy() - X_test.copy()

# 1) Income: overall mean & median
if "annual_income" in X_test.columns and X_test["annual_income"].median() != 0:
    inc_base_mean = X_test["annual_income"].mean()
    inc_delta_mean = (delta["annual_income"].mean() / inc_base_mean) if inc_base_mean != 0 else 0
    inc_delta_med  = (delta["annual_income"].median() / X_test["annual_income"].median())
    bullets.append(f"annual_income: mean change {pct(inc_delta_mean)}, median change {pct(inc_delta_med)}.")

# 2) Income change by sector (worst & best)
if {"sector", "annual_income"}.issubset(X_test.columns):
    g = (X_test_shock["annual_income"] - X_test["annual_income"]).groupby(X_test["sector"]).mean()
    base_by_sec = X_test.groupby("sector")["annual_income"].mean().replace(0, np.nan)
    g_rel = (g / base_by_sec).fillna(0)
    worst_sec, best_sec = g_rel.idxmin(), g_rel.idxmax()
    bullets.append(f"By sector: worst={worst_sec} ({pct(g_rel.loc[worst_sec])}), best={best_sec} ({pct(g_rel.loc[best_sec])}).")

# 3) Employment status: share worsened
if "employment_status" in X_test.columns:
    emp_shift_up = (delta["employment_status"] > 0).mean()
    bullets.append(f"employment_status: {emp_shift_up*100:.1f}% shifted to more precarious categories.")

# 4–7) Other feature changes
for col, label in [
    ("savings_rate", "savings_rate"),
    ("late_payment_12m", "late_payment_12m"),
    ("childcare_cost_share", "childcare_cost_share"),
    ("eldercare_cost_share", "eldercare_cost_share")
]:
    if col in X_test.columns:
        bullets.append(f"{label}: average change {pp(delta[col].mean())}.")

# 8) Income change by region (worst region)
if {"region", "annual_income"}.issubset(X_test.columns):
    gr = (X_test_shock["annual_income"] - X_test["annual_income"]).groupby(X_test["region"]).mean()
    base_by_reg = X_test.groupby("region")["annual_income"].mean().replace(0, np.nan)
    gr_rel = (gr / base_by_reg).fillna(0)
    worst_reg = gr_rel.idxmin()
    bullets.append(f"By region: worst hit region={worst_reg} ({pct(gr_rel.loc[worst_reg])}).")

# 9) Foreign-born: share with worsened employment
if {"foreign_born", "employment_status"}.issubset(X_test.columns):
    mask_fb = X_test["foreign_born"] == 1
    if mask_fb.any():
        fb_worse = (delta.loc[mask_fb, "employment_status"] > 0).mean()
        bullets.append(f"foreign_born: {fb_worse*100:.1f}% experienced worsening employment status.")

# 10) Multigenerational vs non-multigenerational households
if {"multigen_household", "annual_income"}.issubset(X_test.columns):
    d_inc = (X_test_shock["annual_income"] - X_test["annual_income"])
    by_multi = d_inc.groupby(X_test["multigen_household"]).mean()
    base_means = X_test.groupby("multigen_household")["annual_income"].mean().replace(0, np.nan)
    if set(by_multi.index) >= {0,1}:
        rel0 = (by_multi.loc[0] / base_means.loc[0])
        rel1 = (by_multi.loc[1] / base_means.loc[1])
        bullets.append(f"multigen_household: income change non-multigen={pct(rel0)}, multigen={pct(rel1)}.")

print("\nChanges under shock:")
for b in bullets[:10]:
    print(f"- {b}")


# [Cell6] Visualize class changes (Matplotlib, Blues style)
import matplotlib.pyplot as plt
import numpy as np

def plot_transition_heatmap_mat(trans_df, title="Class Transition Matrix Under Shock"):
    labels = sorted(list(set(trans_df.index) | set(trans_df.columns)))
    trans_df = trans_df.reindex(index=labels, columns=labels, fill_value=0.0)
    mat = trans_df.values  # in %

    fig, ax = plt.subplots(figsize=(6, 5))
    im = ax.imshow(mat, cmap="Blues", aspect="auto", vmin=0, vmax=100)
    ax.set_title(title)
    ax.set_xlabel("Predicted (After Shock)")
    ax.set_ylabel("Predicted (Before Shock)")
    ax.set_xticks(np.arange(len(labels)))
    ax.set_yticks(np.arange(len(labels)))
    ax.set_xticklabels(labels)
    ax.set_yticklabels(labels)

    for i in range(mat.shape[0]):
        for j in range(mat.shape[1]):
            val = mat[i, j]
            ax.text(j, i, f"{val:.1f}", ha="center", va="center",
                    color=("white" if val > 50 else "black"), fontsize=9)

    cbar = plt.colorbar(im)
    cbar.set_label("% within row", rotation=90)
    plt.tight_layout()
    plt.show()

plot_transition_heatmap_mat(trans_mat, title="Class Transition Matrix Under Shock")
