import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, roc_auc_score

from google.colab import files
uploaded = files.upload()
import pandas as pd

df = pd.read_csv("household_vulnerability_japan.csv")
print(df.shape)
print(df.head())

# Read the new dataset
df = pd.read_csv("household_vulnerability_japan.csv")

# Quick check
print(df.shape)
print(df.head())


from xgboost import XGBClassifier

pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)

model = XGBClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=pos_weight,
    random_state=42,
    eval_metric="logloss"
)

model.fit(X_train, y_train)

from sklearn.metrics import classification_report, roc_auc_score

y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:,1]

print("Classification Report:\n", classification_report(y_test, y_pred))
print("ROC AUC:", roc_auc_score(y_test, y_proba))

from sklearn.feature_selection import SelectFromModel

selector = SelectFromModel(model, threshold="median", prefit=True)
X_train_selected = selector.transform(X_train)
X_test_selected = selector.transform(X_test)

print("Original features:", X_train.shape[1])
print("Selected features:", X_train_selected.shape[1])

model_selected = XGBClassifier(
    n_estimators=1000,
    learning_rate=0.05,
    max_depth=1,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=pos_weight,
    random_state=42,
    eval_metric="logloss"
)

model_selected.fit(X_train_selected, y_train)

y_pred_sel = model_selected.predict(X_test_selected)
y_proba_sel = model_selected.predict_proba(X_test_selected)[:,1]

print("Classification Report:\n", classification_report(y_test, y_pred_sel))
print("ROC AUC:", roc_auc_score(y_test, y_proba_sel))

import shap
import pandas as pd

# Create DataFrame with selected features
X_test_selected_df = pd.DataFrame(
    X_test_selected,
    columns=X.columns[selector.get_support()]
)

# Use the model trained on selected features
explainer = shap.TreeExplainer(model_selected)

# Compute SHAP values
shap_values = explainer.shap_values(X_test_selected_df)

# If shap_values is a list (binary classification case), take class 1
if isinstance(shap_values, list):
    shap_values = shap_values[1]

# Plot summary
shap.summary_plot(shap_values, X_test_selected_df)
