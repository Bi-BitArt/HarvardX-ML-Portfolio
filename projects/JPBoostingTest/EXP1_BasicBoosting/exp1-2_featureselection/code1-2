# [cell1]
from sklearn.feature_selection import SelectFromModel

# Feature selection using median threshold
selector = SelectFromModel(model, threshold="median", prefit=True)
X_train_selected = selector.transform(X_train)
X_test_selected = selector.transform(X_test)

print("Original features:", X_train.shape[1])
print("Selected features:", X_train_selected.shape[1])

# Retrain model with the same hyperparameters as baseline
model_selected = XGBClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=pos_weight,
    random_state=42,
    eval_metric="logloss"
)

model_selected.fit(X_train_selected, y_train)

# Predictions
y_pred_sel = model_selected.predict(X_test_selected)
y_proba_sel = model_selected.predict_proba(X_test_selected)[:, 1]

# Evaluation
print("Classification Report:\n", classification_report(y_test, y_pred_sel))
print("ROC AUC:", roc_auc_score(y_test, y_proba_sel))

# [cell2]
import pandas as pd

# --- Feature importance and selection summary ---
feat_names = X.columns
importances = model.feature_importances_           # baseline model importances
support = selector.get_support()                   # True if kept

# Build summary DataFrame
feat_df = pd.DataFrame({
    "feature": feat_names,
    "importance": importances,
    "selected": support
}).sort_values("importance", ascending=False)

# Lists of kept/dropped
kept = feat_df.loc[feat_df["selected"], "feature"].tolist()
dropped = feat_df.loc[~feat_df["selected"], "feature"].tolist()

print("Kept features (n={}):".format(len(kept)), kept)
print("\nDropped features (n={}):".format(len(dropped)), dropped)

# Top features by importance
print("\nTop 10 features by importance (baseline model):")
print(feat_df.head(10))
