### Experiment 1-1: Baseline XGBoost Model

#### Data Provenance & Synthesis

The dataset used in **Experiment 1** is entirely synthetic.  
It was generated by the author, inspired by the methodological approach of Salvador et al. (2024), but does **not** use any real household microdata.  

- **Features (22 total):** income, savings, employment status, illness, household composition, housing, etc., sampled from simple statistical distributions.  
- **Target (1 column):** binary label `vulnerable` vs. `otherwise`, assigned using a weighted score where adverse factors (e.g., low income, illness, late payments) increase vulnerability and protective factors (e.g., higher income, higher savings) reduce it.  
- **Purpose:** to provide a reproducible testbed for boosting algorithms under controlled but realistic conditions (AUC ≈ 0.75).

> Reference: Salvador, J. et al., *Use of Boosting Algorithms in Household-Level Poverty Measurement:  
> A Machine Learning Approach to Predict and Classify Household Wealth Quintiles in the Philippines*, 2024.  
> Only the methodological idea is borrowed; the data are fully synthetic.

#### Model Setup

- **Split**: 80% train / 20% test (stratified by target)
  
- **Model**: XGBoost (binary classification)  
  - n_estimators = 100  
  - learning_rate = 0.1  
  - max_depth = 3  
  - subsample = 0.8  
  - colsample_bytree = 0.8  
  - scale_pos_weight = (negatives / positives)  
  - eval_metric = "logloss"  


#### Results
- **Accuracy**: 0.68  
- **ROC AUC**: 0.77  
- **Classification report**: shows reasonably balanced precision/recall across vulnerable and non-vulnerable households (full output omitted here).  

#### Interpretation
- The baseline XGBoost achieves **solid discriminatory power** (AUC > 0.75), indicating that socio-economic vulnerability patterns are detectable.  
- Accuracy (≈0.68) is modest but reasonable given the class imbalance typical in household-level data.  
- This experiment provides a **foundation** for further work on:
  - Feature selection (Exp1-2)  
  - Model interpretability (Exp1-3, SHAP analysis)
  - Parameter tuning for over/underfitting control (Exp3-1)  
