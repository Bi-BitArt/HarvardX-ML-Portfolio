# Install Optuna if not already available
!pip install optuna

import optuna
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score, accuracy_score

# Use the feature-selected dataset (from Exp1-2)
Xtr, Xte = X_train_selected, X_test_selected
ytr, yte = y_train, y_test

def objective(trial):
    # Define the search space
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 50, 500),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
        "max_depth": 1,  # fixed to best setting
        "subsample": trial.suggest_float("subsample", 0.6, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
        "scale_pos_weight": pos_weight,
        "random_state": 42,
        "eval_metric": "logloss",
        "n_jobs": -1,
    }
    
    # Train model
    model = XGBClassifier(**params)
    model.fit(Xtr, ytr)
    
    # Evaluate
    y_pred = model.predict(Xte)
    y_proba = model.predict_proba(Xte)[:, 1]
    auc = roc_auc_score(yte, y_proba)
    acc = accuracy_score(yte, y_pred)
    
    # Report both metrics, but optimize AUC
    trial.set_user_attr("accuracy", acc)
    return auc

# Run optimization (30 trials for a quick run)
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=30)

# Print best results
print("Best ROC AUC:", study.best_value)
print("Best parameters:", study.best_params)
print("Accuracy (for best trial):", study.best_trial.user_attrs["accuracy"])
