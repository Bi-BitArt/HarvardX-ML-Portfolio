 Section 1: Decision Trees I

## Preface
- **Exponential notation**: For instance, the number 8,000,000 (eight million) can be expressed as `8e6` or `8 * 10^6` or `8 Ã— 10^6`.

## Concept Breakdown

- What is a decision tree?

  A decision tree is a machine learning algorithm that can be used for both classification and regression.  
  It is one of the supervised algorithms, characterized by a tree-like structure, where:

  - Each internal node represents a feature or attribute.
  - Each branch represents a decision.
  - Each leaf node represents the outcome or prediction.

- What is classification?

  Classification is the task of predicting a categorical label (class) based on input features.  

  One of the most basic classification models is **logistic regression**, which calculates the probability of belonging to a particular class.

- When does logistic regression work best?

  - The classes are well-separated in the feature space
  - The classification boundary has a nice geometry

  In other words, **linearly separable** in the feature space. That is, a straight line (or hyperplane) can separate the categories effectively.

- What is **Classification Boundaries or Decision Boundaries?

  They are defined where the probabilities of being in class 1 and class 0 are equal, i.e. P(Y=1)=P(Y=0)=1 - P(Y=1), that means P(Y=1)=0.5

## Key Concepts


## Pseudocode Insight


## Reflections


